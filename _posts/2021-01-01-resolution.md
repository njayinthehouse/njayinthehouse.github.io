---
layout: default
title: Thoughtless Aiming
date: 2021-03-17
---

I've recently committed to adopting fleeting long-term goals. The idea is to
pick a long-term goal and run with it like I'm serious about it for as long as
I can before I find a reason to no longer run with it. This model allows for 
me to take risks in choosing my long-term goals. My current knowledge 
encourages me to stay within what I know. My hope is that this mental model
serves as a good balance to finding me a job I can really enjoy and feel
good about.

In line with this model, I have chosen the following as my research creed:
"I will use type theory to study how to model intelligence."

Like most religious creeds, it's vague enough to be open to interpretation, 
yet it seems to embody something deep and reverent. More particularly, I wish
to undertake the following projects along these lines:

1. **Probabilistic type theory and distributed semantics**
   I want to marry probabilistic type theory and Bob Coecke's sentence 
   embeddings. I'm hoping this will give me a deeper understanding of 
   distributional semantics, and teach me more about machine learning, 
   perhaps. I'm not sure it actually will, because they feel like orthogonal
   concepts. Why Bob Coecke's sentence embeddings? They're elegantly
   built by composing word embeddings. I want the compositional model I can
   get. Honestly, I'd like to start at a level below syntax, but that seems
   inconvenient.

2. **Impredicative inquiries**
   I'm keenly interested in when impredicativity leads to inconsistency.
   Impredicativity is a term that shows up so often in type theory, yet it 
   feels like we hardly understand it at all. It leads to inconsistency in 
   several situations, but I feel like I don't properly understand exactly
   when. 

3. **Type Theory in Type Theory**
   If I'm going to use type theory to study (and constrain) intelligent
   agents, I need to be capable of imbuing my type theory with reflective
   capabilities.

I also wish to build up a base in decision theory. I ought to build up a base
in machine learning, particularly RL, but I need to be clever about how I do 
that because I seem to have an aversion to ML textbooks. I'm hoping I can
use probabilistic programming to trick myself into learning about learning. It
would also be a good idea to stay on top of MIRI's work, but only briefly --
it makes no sense to constantly drool over their research agenda without
furthering my own.

At the same time, I will be honing the skills I'm more comfortable with. I will
be studying Dependent Object Types as a vehicle to study dependent types and
proof logics. 

Let's hope I make it somewhere this year.
